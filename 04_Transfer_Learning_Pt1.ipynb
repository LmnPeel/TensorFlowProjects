{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04-Transfer Learning Pt1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOp1/HzeKlOyD6HFjTyclhX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frankjinn/TensorFlowProjects/blob/main/04_Transfer_Learning_Pt1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 04. Transfer Learning with TensorFlow Part 1: Feature Extraction\n",
        "## What we're going to cover\n",
        "\n",
        "We're going to go through the following with TensorFlow:\n",
        "\n",
        "- Introduce transfer learning (a way to beat all of our old self-built models)\n",
        "- Using a smaller dataset to experiment faster (10% of training samples of 10 classes of food)\n",
        "- Build a transfer learning feature extraction model using TensorFlow Hub\n",
        "- Introduce the TensorBoard callback to track model training results\n",
        "- Compare model results using TensorBoard"
      ],
      "metadata": {
        "id": "t7E4bHYtKQGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using a GPU\n",
        "\n",
        "Check if we're using a GPU. It will train faster than just a CPU"
      ],
      "metadata": {
        "id": "UgVgoiRYK9Q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "dmtGpcCxLEZ8",
        "outputId": "3ea2dd7c-a833-4c94-abf6-bb5bc9c8d2dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 10 19:39:35 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    58W / 149W |   7945MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer learning with TensorFlow Hub: Getting great results with 10% of the data\n",
        "If you've been thinking, \"surely someone else has spent the time crafting the right model for the job...\" then you're in luck. \n",
        "\n",
        "For many of the problems you'll want to use deep learning for, chances are, a working model already exists.\n",
        "\n",
        "And the good news is, you can access many of them on TensorFlow Hub.\n",
        "\n",
        "[TensorFlow Hub](https://tfhub.dev/) is a repository for existing model components. It makes it so you can import and use a fully trained model with as little as a URL.\n",
        "\n",
        "Now, I really want to demonstrate the power of transfer learning to you.\n",
        "\n",
        "To do so, what if I told you we could get much of the same results (or better) than our best model has gotten so far with only 10% of the original data, in other words, 10x less data.\n",
        "\n",
        "This seems counterintuitive right?\n",
        "\n",
        "Wouldn't you think more examples of what a picture of food looked like led to better results?\n",
        "\n",
        "And you'd be right if you thought so, generally, more data leads to better results.\n",
        "\n",
        "However, what if you didn't have more data? What if instead of 750 images per class, you had 75 images per class?\n",
        "\n",
        "Collecting 675 more images of a certain class could take a long time.\n",
        "\n",
        "So this is where another major benefit of transfer learning comes in.\n",
        "\n",
        "**Transfer learning often allows you to get great results with less data.**\n",
        "\n",
        "But don't just take my word for it. Let's download a subset of the data we've been using, namely 10% of the training data from the `10_food_classes` dataset and use it to train a food image classifier on.\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-transfer-learning-feature-extraction.png)\n",
        "*What we're working towards building. Taking a pre-trained model and adding our own custom layers on top, extracting all of the underlying patterns learned on another dataset our own images.*\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gsQiy1gULGVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get 10% of the 10 food data\n",
        "import zipfile\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Av0i00KMFrc",
        "outputId": "028e22da-c836-467e-cadb-b768cde90f07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-10 19:39:35--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.70.128, 74.125.202.128, 74.125.69.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.70.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: â€˜10_food_classes_10_percent.zip.1â€™\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   162MB/s    in 1.0s    \n",
            "\n",
            "2022-01-10 19:39:36 (162 MB/s) - â€˜10_food_classes_10_percent.zip.1â€™ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#How many images in each folder\n",
        "import os\n",
        "\n",
        "#Walk through the data\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirnames)} directories, {len(filenames)} images in {dirpath}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l96GGvI-NEQQ",
        "outputId": "ec40516a-9b9f-4869-c8a4-1158abbf0cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories, 0 images in 10_food_classes_10_percent.\n",
            "There are 10 directories, 0 images in 10_food_classes_10_percent/test.\n",
            "There are 0 directories, 250 images in 10_food_classes_10_percent/test/sushi.\n",
            "There are 0 directories, 250 images in 10_food_classes_10_percent/test/grilled_salmon.\n",
            "There are 0 directories, 250 images in 10_food_classes_10_percent/test/chicken_wings.\n",
            "There are 0 directories, 250 images in 10_food_classes_10_percent/test/fried_rice.\n",
            "There are 0 directories, 250 images in 10_food_classes_10_percent/test/ice_cream.\n",
            "There are 0 directories, 250 images in 10_food_classes_10_percent/test/hamburger.\n",
            "There are 0 directories, 250 images in 10_food_classes_10_percent/test/ramen.\n",
            "There are 0 directories, 250 images in 10_food_classes_10_percent/test/pizza.\n",
            "There are 0 directories, 250 images in 10_food_classes_10_percent/test/chicken_curry.\n",
            "There are 0 directories, 250 images in 10_food_classes_10_percent/test/steak.\n",
            "There are 10 directories, 0 images in 10_food_classes_10_percent/train.\n",
            "There are 0 directories, 75 images in 10_food_classes_10_percent/train/sushi.\n",
            "There are 0 directories, 75 images in 10_food_classes_10_percent/train/grilled_salmon.\n",
            "There are 0 directories, 75 images in 10_food_classes_10_percent/train/chicken_wings.\n",
            "There are 0 directories, 75 images in 10_food_classes_10_percent/train/fried_rice.\n",
            "There are 0 directories, 75 images in 10_food_classes_10_percent/train/ice_cream.\n",
            "There are 0 directories, 75 images in 10_food_classes_10_percent/train/hamburger.\n",
            "There are 0 directories, 75 images in 10_food_classes_10_percent/train/ramen.\n",
            "There are 0 directories, 75 images in 10_food_classes_10_percent/train/pizza.\n",
            "There are 0 directories, 75 images in 10_food_classes_10_percent/train/chicken_curry.\n",
            "There are 0 directories, 75 images in 10_food_classes_10_percent/train/steak.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing the data\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "BATCH_SIZE = (32)\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train\"\n",
        "test_dir = \"10_food_classes_10_percent/test\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255.)\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255.)\n",
        "\n",
        "print(\"Training images:\")\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                                          target_size = IMAGE_SHAPE,\n",
        "                                                          batch_size = BATCH_SIZE,\n",
        "                                                          class_mode = \"categorical\")\n",
        "\n",
        "print(\"Testing images:\")\n",
        "test_data = train_datagen.flow_from_directory(test_dir,\n",
        "                                                          target_size = IMAGE_SHAPE,\n",
        "                                                          batch_size = BATCH_SIZE,\n",
        "                                                          class_mode = \"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM-Iz7RfOacT",
        "outputId": "f88c93cd-5cb7-487e-9acd-07f6682f93fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images:\n",
            "Found 750 images belonging to 10 classes.\n",
            "Testing images:\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up callbacks (things to run whilst our model trains)\n",
        "\n",
        "Before we build a model, there's an important concept we're going to get familiar with because it's going to play a key role in our future model building experiments.\n",
        "\n",
        "And that concept is **callbacks**.\n",
        "\n",
        "[Callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks) are extra functionality you can add to your models to be performed during or after training. Some of the most popular callbacks include:\n",
        "* [**Experiment tracking with TensorBoard**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) - log the performance of multiple models and then view and compare these models in a visual way on [TensorBoard](https://www.tensorflow.org/tensorboard) (a dashboard for inspecting neural network parameters). Helpful to compare the results of different models on your data.\n",
        "* [**Model checkpointing**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) - save your model as it trains so you can stop training if needed and come back to continue off where you left. Helpful if training takes a long time and can't be done in one sitting.\n",
        "* [**Early stopping**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) - leave your model training for an arbitrary amount of time and have it stop training automatically when it ceases to improve. Helpful when you've got a large dataset and don't know how long training will take.\n",
        "\n",
        "We'll explore each of these overtime but for this notebook, we'll see how the TensorBoard callback can be used.\n",
        "\n",
        "The TensorBoard callback can be accessed using [`tf.keras.callbacks.TensorBoard()`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard). \n",
        "\n",
        "Its main functionality is saving a model's training performance metrics to a specified `log_dir`.\n",
        "\n",
        "By default, logs are recorded every epoch using the `update_freq='epoch'` parameter. This is a good default since tracking model performance too often can slow down model training.\n",
        "\n",
        "To track our modelling experiments using TensorBoard, let's create a function which creates a TensorBoard callback for us.\n",
        "\n",
        "> ðŸ”‘ **Note:** We create a function for creating a TensorBoard callback because as we'll see later on, each model needs its own TensorBoard callback instance (so the function will create a new one each time it's run).\n",
        "\n"
      ],
      "metadata": {
        "id": "yTKXnNkdQwlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create tensorboard callback (functionized beacuse need to create a new one for each model)\n",
        "import datetime\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir = log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "metadata": {
        "id": "7WZC_jK9RHeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because you're likely to run multiple experiments, it's a good idea to be able to track them in some way.\n",
        "\n",
        "In our case, our function saves a model's performance logs to a directory named `[dir_name]/[experiment_name]/[current_timestamp]`, where:\n",
        "* `dir_name` is the overall logs directory\n",
        "* `experiment_name` is the particular experiment\n",
        "* `current_timestamp` is the time the experiment started based on Python's [`datetime.datetime().now()`](https://docs.python.org/3/library/datetime.html#datetime.datetime.now)\n",
        "\n",
        "> ðŸ”‘ **Note:** Depending on your use case, the above experimenting tracking naming method may work or you might require something more specific. The good news is, the TensorBoard callback makes it easy to track modelling logs as long as you specify where to track them. So you can get as creative as you like with how you name your experiments, just make sure you or your team can understand them.\n",
        "\n"
      ],
      "metadata": {
        "id": "8ntfakVJRtF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating models using TensorFlow Hub\n",
        "\n",
        "In the past we've used TensorFlow to create our own models layer by layer from scratch.\n",
        "\n",
        "Now we're going to do a similar process, except the majority of our model's layers are going to come from [TensorFlow Hub](https://tfhub.dev/).\n",
        "\n",
        "In fact, we're going to use two models from TensorFlow Hub:\n",
        "1. [ResNetV2](https://arxiv.org/abs/1603.05027) -  a state of the art computer vision model architecture from 2016.\n",
        "2. [EfficientNet](https://arxiv.org/abs/1905.11946) - a state of the art computer vision architecture from 2019.\n",
        "\n",
        "State of the art means that at some point, both of these models have achieved the lowest error rate on [ImageNet (ILSVRC-2012-CLS)](http://www.image-net.org/), the gold standard of computer vision benchmarks.\n",
        "\n",
        "You might be wondering, how do you find these models on TensorFlow Hub?\n",
        "\n",
        "Here are the steps I took:\n",
        "\n",
        "1. Go to [tfhub.dev](https://tfhub.dev/).\n",
        "2. Choose your problem domain, e.g. \"Image\" (we're using food images).\n",
        "3. Select your TF version, which in our case is TF2.\n",
        "4. Remove all \"Problem domanin\" filters except for the problem you're working on. \n",
        "  * **Note:** \"Image feature vector\" can be used alongside almost any problem, we'll get to this soon.\n",
        "5. The models listed are all models which could potentially be used for your problem.\n",
        "\n",
        "> ðŸ¤” **Question:** *I see many options for image classification models, how do I know which is best?*\n",
        "\n",
        "You can see a list of state of the art models on [paperswithcode.com](https://www.paperswithcode.com), a resource for collecting the latest in deep learning paper results which have code implementations for the findings they report.\n",
        "\n",
        "Since we're working with images, our target are the [models which perform best on ImageNet](https://paperswithcode.com/sota/image-classification-on-imagenet).\n",
        "\n",
        "You'll probably find not all of the model architectures listed on paperswithcode appear on TensorFlow Hub. And this is okay, we can still use what's available.\n",
        "\n",
        "To find our models, let's narrow down our search using the Architecture tab.\n",
        "\n",
        "6. Select the Architecture tab on TensorFlow Hub and you'll see a dropdown menu of architecture names appear. \n",
        "  * The rule of thumb here is generally, names with larger numbers means better performing models. For example, EfficientNetB4 performs better than EfficientNetB0.\n",
        "    * However, the tradeoff with larger numbers can mean they take longer to compute. \n",
        "7. Select EfficientNetB0 and you should see [something like the following](https://tfhub.dev/s?module-type=image-classification,image-feature-vector&network-architecture=efficientnet-b0&tf-version=tf2):\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-tensorflow-hub-efficientnetb0.png)\n",
        "8. Clicking the one titled \"[efficientnet/b0/feature-vector](https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1)\" brings us to a page with a button that says \"Copy URL\". That URL is what we can use to harness the power of EfficientNetB0.\n",
        "  * Copying the URL should give you something like this: https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\n",
        "\n",
        "> ðŸ¤” **Question:** *I thought we were doing image classification, why do we choose feature vector and not classification?*\n",
        "\n",
        "Great observation. This is where the differnet types of transfer learning come into play, as is, feature extraction and fine-tuning.\n",
        "\n",
        "1. **\"As is\" transfer learning** is when you take a pretrained model as it is and apply it to your task without any changes. \n",
        "\n",
        "  * For example, many computer vision models are pretrained on the ImageNet dataset which contains 1000 different classes of images. This means passing a single image to this model will produce 1000 different prediction probability values (1 for each class). \n",
        "\n",
        "    * This is helpful if you have 1000 classes of image you'd like to classify and they're all the same as the ImageNet classes, however, it's not helpful if you want to classify only a small subset of classes (such as 10 different kinds of food). Model's with `\"/classification\"` in their name on TensorFlow Hub provide this kind of functionality.\n",
        "\n",
        "2. **Feature extraction transfer learning** is when you take the underlying patterns (also called weights) a pretrained model has learned and adjust its outputs to be more suited to your problem. \n",
        "\n",
        "  * For example, say the pretrained model you were using had 236 different layers (EfficientNetB0 has 236 layers), but the top layer outputs 1000 classes because it was pretrained on ImageNet. To adjust this to your own problem, you might remove the original activation layer and replace it with your own but with the right number of output classes. The important part here is that **only the top few layers become trainable, the rest remain frozen**. \n",
        "\n",
        "    * This way all the underlying patterns remain in the rest of the layers and you can utilise them for your own problem. This kind of transfer learning is very helpful when your data is similar to the data a model has been pretrained on.\n",
        "\n",
        "3. **Fine-tuning transfer learning** is when you take the underlying patterns (also called weights) of a pretrained model and adjust (fine-tune) them to your own problem. \n",
        "\n",
        "    * This usually means training **some, many or all** of the layers in the pretrained model. This is useful when you've got a large dataset (e.g. 100+ images per class) where your data is slightly different to the data the original model was trained on.\n",
        "\n",
        "A common workflow is to \"freeze\" all of the learned patterns in the bottom layers of a pretrained model so they're untrainable. And then train the top 2-3 layers of so the pretrained model can adjust its outputs to your custom data (**feature extraction**).\n",
        "\n",
        "After you've trained the top 2-3 layers, you can then gradually \"unfreeze\" more and more layers and run the training process on your own data to further **fine-tune** the pretrained model.\n",
        "\n",
        "> ðŸ¤” **Question:** *Why train only the top 2-3 layers in feature extraction?*\n",
        "\n",
        "The lower a layer is in a computer vision model as in, the closer it is to the input layer, the larger the features it learn. For example, a bottom layer in a computer vision model to identify images of cats or dogs might learn the outline of legs, where as, layers closer to the output might learn the shape of teeth. Often, you'll want the larger features (learned patterns are also called features) to remain, since these are similar for both animals, where as, the differences remain in the more fine-grained features.\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-different-kinds-of-transfer-learning.png)\n",
        "*The different kinds of transfer learning. An original model, a feature extraction model (only top 2-3 layers change) and a fine-tuning model (many or all of original model get changed).*\n",
        "\n",
        "Okay, enough talk, let's see this in action. Once we do, we'll explain what's happening.\n",
        "\n",
        "First we'll import TensorFlow and TensorFlow Hub."
      ],
      "metadata": {
        "id": "JRDwTkOHSBd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "jnkmFqIcVRt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll get the feature vector URLs of two common computer vision architectures, [EfficientNetB0 (2019)](https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1) and [ResNetV250 (2016)](https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4) from TensorFlow Hub using the steps above.\n",
        "\n",
        "We're getting both of these because we're going to compare them to see which performs better on our data.\n",
        "\n",
        "> ðŸ”‘ **Note:** Comparing different model architecture performance on the same data is a very common practice. The simple reason is because you want to know which model performs best for your problem.\n",
        "\n",
        "> **Update:** As of 14 August 2021, [EfficientNet V2 pretrained models are available on TensorFlow Hub](https://tfhub.dev/google/collections/efficientnet_v2/1). The original code in this notebook uses EfficientNet V1, it has been left unchanged. In [my experiments with this dataset](https://github.com/mrdbourke/tensorflow-deep-learning/discussions/166), V1 outperforms V2. Best to experiment with your own data and see what suits you."
      ],
      "metadata": {
        "id": "SEyg7pONVYGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Resnet 50 V2 feature vector\n",
        "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
        "\n",
        "#original: EfficientNetB0 feature vector (version 1)\n",
        "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\""
      ],
      "metadata": {
        "id": "n_oXvH6tVgVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(model_url, num_classes = 10):\n",
        "    \"\"\"Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n",
        "  \n",
        "    Args:\n",
        "      model_url (str): A TensorFlow Hub feature extraction URL.\n",
        "      num_classes (int): Number of output neurons in output layer,\n",
        "        should be equal to number of target classes, default 10.\n",
        "\n",
        "    Returns:\n",
        "      An uncompiled Keras Sequential model with model_url as feature\n",
        "      extractor layer and Dense output layer with num_classes outputs.\n",
        "    \"\"\"\n",
        "    #Download the pretrained model and save it as a Keras Layer\n",
        "    feature_extractor_layer = hub.KerasLayer(model_url,\n",
        "                                            trainable = False, #Freeze the underlying patterns\n",
        "                                            name = \"feature_extration_layer\",\n",
        "                                            input_shape = IMAGE_SHAPE + (3,)) # Adds 3 colour channels\n",
        "    #Create own model\n",
        "    model = tf.keras.Sequential([\n",
        "              feature_extractor_layer,\n",
        "              layers.Dense(num_classes, activation = 'softmax', name = 'output_layer')                  \n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "55pWEWocVwsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create model\n",
        "resnet_model = create_model(resnet_url, num_classes = train_data_10_percent.num_classes)\n",
        "\n",
        "#Compile\n",
        "resnet_model.compile(loss = 'CategoricalCrossentropy',\n",
        "                     optimizer = tf.keras.optimizers.Adam(),\n",
        "                     metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "B61F7mYpXSPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-resnet-feature-extractor.png)\n",
        "*What our current model looks like. A ResNet50V2 backbone with a custom dense layer on top (10 classes instead of 1000 ImageNet classes). **Note:** The Image shows ResNet34 instead of ResNet50. **Image source:** https://arxiv.org/abs/1512.03385.*\n",
        "\n",
        "Beautiful. Time to fit the model.\n",
        "\n",
        "We've got the training data ready in `train_data_10_percent` as well as the test data saved as `test_data`.\n",
        "\n",
        "But before we call the fit function, there's one more thing we're going to add, a callback. More specifically, a TensorBoard callback so we can track the performance of our model on TensorBoard.\n",
        "\n",
        "We can add a callback to our model by using the `callbacks` parameter in the fit function.\n",
        "\n",
        "In our case, we'll pass the `callbacks` parameter the `create_tensorboard_callback()` we created earlier with some specific inputs so we know what experiments we're running.\n",
        "\n",
        "Let's keep this experiment short and train for 5 epochs."
      ],
      "metadata": {
        "id": "sAXkcPrOZout"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model\n",
        "resnet_history = resnet_model.fit(train_data_10_percent,\n",
        "                                  epochs = 5,\n",
        "                                  steps_per_epoch = len(train_data_10_percent),\n",
        "                                  validation_data = test_data,\n",
        "                                  callbacks = [create_tensorboard_callback(dir_name = \"tensorflow_hub\", # save experiment logs here\n",
        "                                                                           experiment_name = \"resnet50V2\")]) # name of log files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alKs5ADXZ2nN",
        "outputId": "50aadb73-5089-4189-97fa-4afca1212f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: tensorflow_hub/resnet50V2/20220110-193942\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 27s 963ms/step - loss: 1.8656 - accuracy: 0.3840 - val_loss: 1.1363 - val_accuracy: 0.6556\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 21s 920ms/step - loss: 0.8446 - accuracy: 0.7680 - val_loss: 0.8263 - val_accuracy: 0.7404\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 21s 914ms/step - loss: 0.6013 - accuracy: 0.8267 - val_loss: 0.7480 - val_accuracy: 0.7592\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 21s 912ms/step - loss: 0.4565 - accuracy: 0.8840 - val_loss: 0.6976 - val_accuracy: 0.7780\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 26s 1s/step - loss: 0.3703 - accuracy: 0.9120 - val_loss: 0.6730 - val_accuracy: 0.7820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If you wanted to, you could really turn this into a helper function to load in with a helper.py script...\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the validation and training data separately\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "  \"\"\" \n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();"
      ],
      "metadata": {
        "id": "nMZT1r--ct1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(resnet_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "3qSV4QZcde02",
        "outputId": "cb3c1844-16c5-4dfd-b1a8-ed05be704139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Resnet summary\n",
        "resnet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTyNAZGDdhfy",
        "outputId": "9b675261-bd80-4fdf-e208-3de8428ac250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " feature_extration_layer (Ke  (None, 2048)             23564800  \n",
            " rasLayer)                                                       \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create model\n",
        "efficientnet_model = create_model(model_url = efficientnet_url,\n",
        "                                  num_classes = train_data_10_percent.num_classes)\n",
        "\n",
        "#Compile EfficientNet model\n",
        "efficientnet_model.compile(loss = 'categorical_crossentropy',\n",
        "                           optimizer = tf.keras.optimizers.Adam(),\n",
        "                           metrics = ['accuracy'])\n",
        "\n",
        "#Fit EfficientNet model\n",
        "efficientnet_history = efficientnet_model.fit(train_data_10_percent,\n",
        "                                              epochs = 5,\n",
        "                                              steps_per_epoch = len(train_data_10_percent),\n",
        "                                              validation_data = test_data,\n",
        "                                              validation_steps = len(test_data),\n",
        "                                              callbacks = [create_tensorboard_callback(dir_name = \"tensorflow_hub\",\n",
        "                                                                                       #Track logs under different experiment name\n",
        "                                                                                       experiment_name = \"efficientnetB0\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfeXjseogTJh",
        "outputId": "19e49d24-f15c-4266-9958-9d2ecf650cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: tensorflow_hub/efficientnetB0/20220110-201019\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 33s 918ms/step - loss: 1.8277 - accuracy: 0.4520 - val_loss: 1.2750 - val_accuracy: 0.7480\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 19s 827ms/step - loss: 1.0479 - accuracy: 0.7800 - val_loss: 0.8578 - val_accuracy: 0.8244\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 19s 816ms/step - loss: 0.7498 - accuracy: 0.8333 - val_loss: 0.6941 - val_accuracy: 0.8448\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 19s 811ms/step - loss: 0.6071 - accuracy: 0.8547 - val_loss: 0.6069 - val_accuracy: 0.8532\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 19s 821ms/step - loss: 0.5153 - accuracy: 0.8773 - val_loss: 0.5546 - val_accuracy: 0.8644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukdhTrwOhIpH",
        "outputId": "6e650c4b-43a9-487f-cbe7-738f8652de77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " feature_extration_layer (Ke  (None, 1280)             4049564   \n",
            " rasLayer)                                                       \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,062,374\n",
            "Trainable params: 12,810\n",
            "Non-trainable params: 4,049,564\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing models using TensorBoard\n",
        "\n",
        "Alright, even though we've already compared the performance of our two models by looking at the accuracy scores. But what if you had more than two models? \n",
        "\n",
        "That's where an experiment tracking tool like [TensorBoard](https://www.tensorflow.org/tensorboard) (preinstalled in Google Colab) comes in.\n",
        "\n",
        "The good thing is, since we set up a TensorBoard callback, all of our model's training logs have been saved automatically. To visualize them, we can upload the results to [TensorBoard.dev](https://tensorboard.dev/).\n",
        "\n",
        "Uploading your results to TensorBoard.dev enables you to track and share multiple different modelling experiments. So if you needed to show someone your results, you could send them a link to your TensorBoard.dev as well as the accompanying Colab notebook.\n",
        "\n",
        "> ðŸ”‘ **Note:** These experiments are public, do not upload sensitive data. You can delete experiments if needed.\n",
        "\n",
        "### Uploading experiments to TensorBoard\n",
        "\n",
        "To upload a series of TensorFlow logs to TensorBoard, we can use the following command:\n",
        "\n",
        "```\n",
        "Upload TensorBoard dev records\n",
        "\n",
        "!tensorboard dev upload --logdir ./tensorflow_hub/ \\\n",
        "  --name \"EfficientNetB0 vs. ResNet50V2\" \\ \n",
        "  --description \"Comparing two different TF Hub feature extraction models architectures using 10% of training images\" \\ \n",
        "  --one_shot\n",
        "```\n",
        "\n",
        "Where:\n",
        "* `--logdir` is the target upload directory\n",
        "* `--name` is the name of the experiment\n",
        "* `--description` is a brief description of the experiment\n",
        "* `--one_shot` exits the TensorBoard uploader once uploading is finished\n",
        "\n",
        "Running the `tensorboard dev upload` command will first ask you to authorize the upload to TensorBoard.dev. After you've authorized the upload, your log files will be uploaded."
      ],
      "metadata": {
        "id": "pc7-68Vo0mVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload TensorBoard dev records\n",
        "!tensorboard dev upload --logdir ./tensorflow_hub/ \\\n",
        "  --name \"EfficientNet80 vs ResNet50V2\" \\\n",
        "  --description \"Comparing two different TF Hub feature extraction models architectures using 10% of training images\" \\\n",
        "  --one_shot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W11xywNg1-lR",
        "outputId": "f9a64135-8b42-48a6-8b84-8d04eeb529fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "***** TensorBoard Uploader *****\n",
            "\n",
            "This will upload your TensorBoard logs to https://tensorboard.dev/ from\n",
            "the following directory:\n",
            "\n",
            "./tensorflow_hub/\n",
            "\n",
            "This TensorBoard will be visible to everyone. Do not upload sensitive\n",
            "data.\n",
            "\n",
            "Your use of this service is subject to Google's Terms of Service\n",
            "<https://policies.google.com/terms> and Privacy Policy\n",
            "<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n",
            "<https://tensorboard.dev/policy/terms/>.\n",
            "\n",
            "This notice will not be shown again while you are logged into the uploader.\n",
            "To log out, run `tensorboard dev auth revoke`.\n",
            "\n",
            "Continue? (yes/NO) yes\n",
            "\n",
            "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=373649185512-8v619h5kft38l4456nm2dj4ubeqsrvh6.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email&state=rXCOl3F6DOeXQrybJj6dEm52gwZvYZ&prompt=consent&access_type=offline\n",
            "Enter the authorization code: 4/1AX4XfWgIR73D-kp1-u7OstEQOjMwxEL1gJmAAWq_Bxc3AaMpon5eONuBqos\n",
            "\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/xjgkT8nWSMiqgYNjjhVG1g/\n",
            "\n",
            "\u001b[1m[2022-01-10T21:17:26]\u001b[0m Started scanning logdir.\n",
            "\u001b[1m[2022-01-10T21:17:29]\u001b[0m Total uploaded: 90 scalars, 0 tensors, 3 binary objects (7.4 MB)\n",
            "\u001b[1m[2022-01-10T21:17:29]\u001b[0m Done scanning logdir.\n",
            "\n",
            "\n",
            "Done. View your TensorBoard at https://tensorboard.dev/experiment/xjgkT8nWSMiqgYNjjhVG1g/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every time you upload something to TensorBoad.dev you'll get a new experiment ID. The experiment ID will look something like this: https://tensorboard.dev/experiment/73taSKxXQeGPQsNBcVvY3g/ (this is the actual experiment from this notebook).\n",
        "\n",
        "If you upload the same directory again, you'll get a new experiment ID to go along with it.\n",
        "\n",
        "This means to track your experiments, you may want to look into how you name your uploads. That way when you find them on TensorBoard.dev you can tell what happened during each experiment (e.g. \"efficientnet0_10_percent_data\").\n",
        "\n",
        "### Listing experiments you've saved to TensorBoard\n",
        "\n",
        "To see all of the experiments you've uploaded you can use the command:\n",
        "\n",
        "```tensorboard dev list```"
      ],
      "metadata": {
        "id": "WDn0R_KO2XRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out experiments\n",
        "!tensorboard dev list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-N42o9p2hWD",
        "outputId": "7433c516-32a5-4335-b367-737629069e35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://tensorboard.dev/experiment/xjgkT8nWSMiqgYNjjhVG1g/\n",
            "\tName                 EfficientNet80 vs ResNet50V2\n",
            "\tDescription          Comparing two different TF Hub feature extraction models architectures using 10% of training images\n",
            "\tId                   xjgkT8nWSMiqgYNjjhVG1g\n",
            "\tCreated              2022-01-10 21:17:26 (1 minute ago)\n",
            "\tUpdated              2022-01-10 21:17:29 (1 minute ago)\n",
            "\tRuns                 6\n",
            "\tTags                 5\n",
            "\tScalars              90\n",
            "\tTensor bytes         0\n",
            "\tBinary object bytes  7764780\n",
            "Total: 1 experiment(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deleting experiments from TensorBoard\n",
        "\n",
        "Remember, all uploads to TensorBoard.dev are public, so to delete an experiment you can use the command:\n",
        "\n",
        "`tensorboard dev delete --experiment_id [INSERT_EXPERIMENT_ID]`\n"
      ],
      "metadata": {
        "id": "E1m6f3oB23Xy"
      }
    }
  ]
}